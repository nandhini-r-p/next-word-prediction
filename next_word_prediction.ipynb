{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "6134200d",
      "metadata": {
        "id": "6134200d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "# Reading corpus the text file\n",
        "with open(\"/content/drive/MyDrive/Next word prediction using RNN/bangalore.txt\", 'r', encoding='utf-8') as myfile:\n",
        "    mytext = myfile.read()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "XTfEhJCbJy6M"
      },
      "id": "XTfEhJCbJy6M",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "ef3afb16",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "ef3afb16",
        "outputId": "44b95c7a-0b56-4d1e-eba0-79f196e28a3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The bustling city of Bengaluru, often referred to as the \"Silicon Valley of India,\" is a vibrant hub of technological innovation and cultural diversity. Nestled amidst lush greenery, the city boasts a cosmopolitan population with a strong entrepreneurial spirit. From its towering IT companies and bustling startup scene to its historic temples and vibrant street art, Bengaluru offers a unique blend of the modern and the traditional.\\n\\nThe city\\'s infrastructure reflects its rapid growth, with a well-developed network of metro lines and flyovers efficiently navigating the urban landscape. Bustling markets and contemporary shopping malls cater to every need, while serene parks and sprawling gardens provide a welcome respite from the city\\'s energy.\\n\\nBengaluru\\'s culinary scene is a melting pot of flavors, offering a delectable mix of South Indian staples like dosa and idli alongside international cuisines from around the globe. The city\\'s vibrant nightlife caters to diverse tastes, with trendy pubs and rooftop bars offering live music and entertainment for all.\\n\\nBeyond the concrete jungle, Bengaluru boasts a rich heritage evident in its historical landmarks like the majestic Bangalore Palace and the serene Lalbagh Botanical Gardens. The city\\'s art scene flourishes with numerous galleries and museums showcasing both traditional and contemporary works.\\n\\nBengaluru\\'s residents are known for their friendly and welcoming nature, readily embracing the city\\'s multicultural spirit. The city\\'s educational institutions attract students from across the country, contributing to its intellectual vibrancy.\\n\\nDespite its rapid growth, Bengaluru faces challenges like traffic congestion and environmental concerns. However, the city\\'s residents demonstrate a strong sense of community, actively working towards sustainable solutions and social development initiatives.\\n\\nAs Bengaluru continues to evolve, one thing remains constant: its dynamic energy and entrepreneurial spirit. The city serves as a testament to India\\'s rapid modernization and holds immense potential for future growth, making it a truly remarkable place to live, work, and explore.\\n\\nThis paragraph, along with variations you can create by changing sentence structure, word choice, and specific details, provides approximately 500 words of text for training your machine learning model. Remember to tailor the content further based on your specific model\\'s purpose and the type of data it requires.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "mytext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "3f0d8c7b",
      "metadata": {
        "id": "3f0d8c7b"
      },
      "outputs": [],
      "source": [
        "mytokenizer = Tokenizer()\n",
        "mytokenizer.fit_on_texts([mytext])\n",
        "total_words = len(mytokenizer.word_index) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "c67d349f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c67d349f",
        "outputId": "3a5ca9bf-de2b-47cf-99ff-c0c2a5404a05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'and': 2,\n",
              " 'a': 3,\n",
              " 'of': 4,\n",
              " 'to': 5,\n",
              " 'its': 6,\n",
              " \"city's\": 7,\n",
              " 'bengaluru': 8,\n",
              " 'with': 9,\n",
              " 'from': 10,\n",
              " 'for': 11,\n",
              " 'bustling': 12,\n",
              " 'city': 13,\n",
              " 'as': 14,\n",
              " 'vibrant': 15,\n",
              " 'spirit': 16,\n",
              " 'it': 17,\n",
              " 'scene': 18,\n",
              " 'rapid': 19,\n",
              " 'growth': 20,\n",
              " 'like': 21,\n",
              " 'is': 22,\n",
              " 'boasts': 23,\n",
              " 'strong': 24,\n",
              " 'entrepreneurial': 25,\n",
              " 'art': 26,\n",
              " 'traditional': 27,\n",
              " 'contemporary': 28,\n",
              " 'serene': 29,\n",
              " 'gardens': 30,\n",
              " 'energy': 31,\n",
              " \"bengaluru's\": 32,\n",
              " 'offering': 33,\n",
              " 'live': 34,\n",
              " 'residents': 35,\n",
              " 'specific': 36,\n",
              " 'your': 37,\n",
              " 'often': 38,\n",
              " 'referred': 39,\n",
              " 'silicon': 40,\n",
              " 'valley': 41,\n",
              " 'india': 42,\n",
              " 'hub': 43,\n",
              " 'technological': 44,\n",
              " 'innovation': 45,\n",
              " 'cultural': 46,\n",
              " 'diversity': 47,\n",
              " 'nestled': 48,\n",
              " 'amidst': 49,\n",
              " 'lush': 50,\n",
              " 'greenery': 51,\n",
              " 'cosmopolitan': 52,\n",
              " 'population': 53,\n",
              " 'towering': 54,\n",
              " 'companies': 55,\n",
              " 'startup': 56,\n",
              " 'historic': 57,\n",
              " 'temples': 58,\n",
              " 'street': 59,\n",
              " 'offers': 60,\n",
              " 'unique': 61,\n",
              " 'blend': 62,\n",
              " 'modern': 63,\n",
              " 'infrastructure': 64,\n",
              " 'reflects': 65,\n",
              " 'well': 66,\n",
              " 'developed': 67,\n",
              " 'network': 68,\n",
              " 'metro': 69,\n",
              " 'lines': 70,\n",
              " 'flyovers': 71,\n",
              " 'efficiently': 72,\n",
              " 'navigating': 73,\n",
              " 'urban': 74,\n",
              " 'landscape': 75,\n",
              " 'markets': 76,\n",
              " 'shopping': 77,\n",
              " 'malls': 78,\n",
              " 'cater': 79,\n",
              " 'every': 80,\n",
              " 'need': 81,\n",
              " 'while': 82,\n",
              " 'parks': 83,\n",
              " 'sprawling': 84,\n",
              " 'provide': 85,\n",
              " 'welcome': 86,\n",
              " 'respite': 87,\n",
              " 'culinary': 88,\n",
              " 'melting': 89,\n",
              " 'pot': 90,\n",
              " 'flavors': 91,\n",
              " 'delectable': 92,\n",
              " 'mix': 93,\n",
              " 'south': 94,\n",
              " 'indian': 95,\n",
              " 'staples': 96,\n",
              " 'dosa': 97,\n",
              " 'idli': 98,\n",
              " 'alongside': 99,\n",
              " 'international': 100,\n",
              " 'cuisines': 101,\n",
              " 'around': 102,\n",
              " 'globe': 103,\n",
              " 'nightlife': 104,\n",
              " 'caters': 105,\n",
              " 'diverse': 106,\n",
              " 'tastes': 107,\n",
              " 'trendy': 108,\n",
              " 'pubs': 109,\n",
              " 'rooftop': 110,\n",
              " 'bars': 111,\n",
              " 'music': 112,\n",
              " 'entertainment': 113,\n",
              " 'all': 114,\n",
              " 'beyond': 115,\n",
              " 'concrete': 116,\n",
              " 'jungle': 117,\n",
              " 'rich': 118,\n",
              " 'heritage': 119,\n",
              " 'evident': 120,\n",
              " 'in': 121,\n",
              " 'historical': 122,\n",
              " 'landmarks': 123,\n",
              " 'majestic': 124,\n",
              " 'bangalore': 125,\n",
              " 'palace': 126,\n",
              " 'lalbagh': 127,\n",
              " 'botanical': 128,\n",
              " 'flourishes': 129,\n",
              " 'numerous': 130,\n",
              " 'galleries': 131,\n",
              " 'museums': 132,\n",
              " 'showcasing': 133,\n",
              " 'both': 134,\n",
              " 'works': 135,\n",
              " 'are': 136,\n",
              " 'known': 137,\n",
              " 'their': 138,\n",
              " 'friendly': 139,\n",
              " 'welcoming': 140,\n",
              " 'nature': 141,\n",
              " 'readily': 142,\n",
              " 'embracing': 143,\n",
              " 'multicultural': 144,\n",
              " 'educational': 145,\n",
              " 'institutions': 146,\n",
              " 'attract': 147,\n",
              " 'students': 148,\n",
              " 'across': 149,\n",
              " 'country': 150,\n",
              " 'contributing': 151,\n",
              " 'intellectual': 152,\n",
              " 'vibrancy': 153,\n",
              " 'despite': 154,\n",
              " 'faces': 155,\n",
              " 'challenges': 156,\n",
              " 'traffic': 157,\n",
              " 'congestion': 158,\n",
              " 'environmental': 159,\n",
              " 'concerns': 160,\n",
              " 'however': 161,\n",
              " 'demonstrate': 162,\n",
              " 'sense': 163,\n",
              " 'community': 164,\n",
              " 'actively': 165,\n",
              " 'working': 166,\n",
              " 'towards': 167,\n",
              " 'sustainable': 168,\n",
              " 'solutions': 169,\n",
              " 'social': 170,\n",
              " 'development': 171,\n",
              " 'initiatives': 172,\n",
              " 'continues': 173,\n",
              " 'evolve': 174,\n",
              " 'one': 175,\n",
              " 'thing': 176,\n",
              " 'remains': 177,\n",
              " 'constant': 178,\n",
              " 'dynamic': 179,\n",
              " 'serves': 180,\n",
              " 'testament': 181,\n",
              " \"india's\": 182,\n",
              " 'modernization': 183,\n",
              " 'holds': 184,\n",
              " 'immense': 185,\n",
              " 'potential': 186,\n",
              " 'future': 187,\n",
              " 'making': 188,\n",
              " 'truly': 189,\n",
              " 'remarkable': 190,\n",
              " 'place': 191,\n",
              " 'work': 192,\n",
              " 'explore': 193,\n",
              " 'this': 194,\n",
              " 'paragraph': 195,\n",
              " 'along': 196,\n",
              " 'variations': 197,\n",
              " 'you': 198,\n",
              " 'can': 199,\n",
              " 'create': 200,\n",
              " 'by': 201,\n",
              " 'changing': 202,\n",
              " 'sentence': 203,\n",
              " 'structure': 204,\n",
              " 'word': 205,\n",
              " 'choice': 206,\n",
              " 'details': 207,\n",
              " 'provides': 208,\n",
              " 'approximately': 209,\n",
              " '500': 210,\n",
              " 'words': 211,\n",
              " 'text': 212,\n",
              " 'training': 213,\n",
              " 'machine': 214,\n",
              " 'learning': 215,\n",
              " 'model': 216,\n",
              " 'remember': 217,\n",
              " 'tailor': 218,\n",
              " 'content': 219,\n",
              " 'further': 220,\n",
              " 'based': 221,\n",
              " 'on': 222,\n",
              " \"model's\": 223,\n",
              " 'purpose': 224,\n",
              " 'type': 225,\n",
              " 'data': 226,\n",
              " 'requires': 227}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "mytokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "c4c696fe",
      "metadata": {
        "id": "c4c696fe"
      },
      "outputs": [],
      "source": [
        "my_input_sequences = []\n",
        "for line in mytext.split('\\n'):\n",
        "    #print(line)\n",
        "    token_list = mytokenizer.texts_to_sequences([line])[0]\n",
        "    #print(token_list)\n",
        "    for i in range(1, len(token_list)):\n",
        "        my_n_gram_sequence = token_list[:i+1]\n",
        "        #print(my_n_gram_sequence)\n",
        "        my_input_sequences.append(my_n_gram_sequence)\n",
        "        #print(input_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "bd13dce9",
      "metadata": {
        "id": "bd13dce9"
      },
      "outputs": [],
      "source": [
        "max_sequence_len = max([len(seq) for seq in my_input_sequences])\n",
        "input_sequences = np.array(pad_sequences(my_input_sequences, maxlen=max_sequence_len, padding='pre'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "cf398edc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf398edc",
        "outputId": "f8e6db1b-cdc2-4f92-eaff-c11352116047"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 12, 13],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "input_sequences[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "ce62fdd7",
      "metadata": {
        "id": "ce62fdd7"
      },
      "outputs": [],
      "source": [
        "X = input_sequences[:, :-1]\n",
        "y = input_sequences[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "6385ea38",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6385ea38",
        "outputId": "3b6dcb1e-059f-4522-eba0-11bc778391db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 12],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "X[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "bc113505",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc113505",
        "outputId": "94a0e9bd-c0f2-454b-e1c7-09f9225c5ef9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 12,  13,   4,   8,  38,  39,   5,  14,   1,  40,  41,   4,  42,\n",
              "        22,   3,  15,  43,   4,  44,  45,   2,  46,  47,  48,  49,  50,\n",
              "        51,   1,  13,  23,   3,  52,  53,   9,   3,  24,  25,  16,  10,\n",
              "         6,  54,  17,  55,   2,  12,  56,  18,   5,   6,  57,  58,   2,\n",
              "        15,  59,  26,   8,  60,   3,  61,  62,   4,   1,  63,   2,   1,\n",
              "        27,   7,  64,  65,   6,  19,  20,   9,   3,  66,  67,  68,   4,\n",
              "        69,  70,   2,  71,  72,  73,   1,  74,  75,  12,  76,   2,  28,\n",
              "        77,  78,  79,   5,  80,  81,  82,  29,  83,   2,  84,  30,  85,\n",
              "         3,  86,  87,  10,   1,   7,  31,  88,  18,  22,   3,  89,  90,\n",
              "         4,  91,  33,   3,  92,  93,   4,  94,  95,  96,  21,  97,   2,\n",
              "        98,  99, 100, 101,  10, 102,   1, 103,   1,   7,  15, 104, 105,\n",
              "         5, 106, 107,   9, 108, 109,   2, 110, 111,  33,  34, 112,   2,\n",
              "       113,  11, 114,   1, 116, 117,   8,  23,   3, 118, 119, 120, 121,\n",
              "         6, 122, 123,  21,   1, 124, 125, 126,   2,   1,  29, 127, 128,\n",
              "        30,   1,   7,  26,  18, 129,   9, 130, 131,   2, 132, 133, 134,\n",
              "        27,   2,  28, 135,  35, 136, 137,  11, 138, 139,   2, 140, 141,\n",
              "       142, 143,   1,   7, 144,  16,   1,   7, 145, 146, 147, 148,  10,\n",
              "       149,   1, 150, 151,   5,   6, 152, 153,   6,  19,  20,   8, 155,\n",
              "       156,  21, 157, 158,   2, 159, 160, 161,   1,   7,  35, 162,   3,\n",
              "        24, 163,   4, 164, 165, 166, 167, 168, 169,   2, 170, 171, 172,\n",
              "         8, 173,   5, 174, 175, 176, 177, 178,   6, 179,  31,   2,  25,\n",
              "        16,   1,  13, 180,  14,   3, 181,   5, 182,  19, 183,   2, 184,\n",
              "       185, 186,  11, 187,  20, 188,  17,   3, 189, 190, 191,   5,  34,\n",
              "       192,   2, 193, 195, 196,   9, 197, 198, 199, 200, 201, 202, 203,\n",
              "       204, 205, 206,   2,  36, 207, 208, 209, 210, 211,   4, 212,  11,\n",
              "       213,  37, 214, 215, 216, 217,   5, 218,   1, 219, 220, 221, 222,\n",
              "        37,  36, 223, 224,   2,   1, 225,   4, 226,  17, 227], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "2ef255b4",
      "metadata": {
        "id": "2ef255b4"
      },
      "outputs": [],
      "source": [
        "y = np.array(tf.keras.utils.to_categorical(y, num_classes=total_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "1e13587e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e13587e",
        "outputId": "31285e23-8d0b-4d27-86b2-fe9d077f13d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "y[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "28ac495c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28ac495c",
        "outputId": "b65c5eb6-02f7-435f-eb4f-38742674125f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 66, 100)           22800     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 150)               150600    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 228)               34428     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 207828 (811.83 KB)\n",
            "Trainable params: 207828 (811.83 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "912b7746",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "912b7746",
        "outputId": "2f39628b-1bb5-4ece-d06d-e60493e30e55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "11/11 [==============================] - 5s 208ms/step - loss: 5.4266 - accuracy: 0.0372\n",
            "Epoch 2/500\n",
            "11/11 [==============================] - 3s 245ms/step - loss: 5.3024 - accuracy: 0.0630\n",
            "Epoch 3/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 5.1632 - accuracy: 0.0544\n",
            "Epoch 4/500\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 5.0653 - accuracy: 0.0516\n",
            "Epoch 5/500\n",
            "11/11 [==============================] - 1s 114ms/step - loss: 5.0366 - accuracy: 0.0602\n",
            "Epoch 6/500\n",
            "11/11 [==============================] - 1s 113ms/step - loss: 5.0028 - accuracy: 0.0544\n",
            "Epoch 7/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 4.9650 - accuracy: 0.0860\n",
            "Epoch 8/500\n",
            "11/11 [==============================] - 1s 116ms/step - loss: 4.9119 - accuracy: 0.0831\n",
            "Epoch 9/500\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 4.8519 - accuracy: 0.0888\n",
            "Epoch 10/500\n",
            "11/11 [==============================] - 2s 161ms/step - loss: 4.7747 - accuracy: 0.0888\n",
            "Epoch 11/500\n",
            "11/11 [==============================] - 3s 246ms/step - loss: 4.6864 - accuracy: 0.0974\n",
            "Epoch 12/500\n",
            "11/11 [==============================] - 2s 200ms/step - loss: 4.5859 - accuracy: 0.1060\n",
            "Epoch 13/500\n",
            "11/11 [==============================] - 1s 115ms/step - loss: 4.4686 - accuracy: 0.1117\n",
            "Epoch 14/500\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 4.3296 - accuracy: 0.1117\n",
            "Epoch 15/500\n",
            "11/11 [==============================] - 1s 113ms/step - loss: 4.1768 - accuracy: 0.1347\n",
            "Epoch 16/500\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 4.0153 - accuracy: 0.1547\n",
            "Epoch 17/500\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 3.8437 - accuracy: 0.1547\n",
            "Epoch 18/500\n",
            "11/11 [==============================] - 1s 116ms/step - loss: 3.6737 - accuracy: 0.1691\n",
            "Epoch 19/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 3.4912 - accuracy: 0.1748\n",
            "Epoch 20/500\n",
            "11/11 [==============================] - 3s 238ms/step - loss: 3.3225 - accuracy: 0.1948\n",
            "Epoch 21/500\n",
            "11/11 [==============================] - 2s 201ms/step - loss: 3.1423 - accuracy: 0.2034\n",
            "Epoch 22/500\n",
            "11/11 [==============================] - 1s 114ms/step - loss: 2.9569 - accuracy: 0.2521\n",
            "Epoch 23/500\n",
            "11/11 [==============================] - 1s 112ms/step - loss: 2.8153 - accuracy: 0.3037\n",
            "Epoch 24/500\n",
            "11/11 [==============================] - 1s 113ms/step - loss: 2.6477 - accuracy: 0.3324\n",
            "Epoch 25/500\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 2.4959 - accuracy: 0.4011\n",
            "Epoch 26/500\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 2.3573 - accuracy: 0.4069\n",
            "Epoch 27/500\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 2.2288 - accuracy: 0.4642\n",
            "Epoch 28/500\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 2.0905 - accuracy: 0.5158\n",
            "Epoch 29/500\n",
            "11/11 [==============================] - 2s 191ms/step - loss: 1.9726 - accuracy: 0.5817\n",
            "Epoch 30/500\n",
            "11/11 [==============================] - 3s 236ms/step - loss: 1.8508 - accuracy: 0.6132\n",
            "Epoch 31/500\n",
            "11/11 [==============================] - 2s 137ms/step - loss: 1.7562 - accuracy: 0.6361\n",
            "Epoch 32/500\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 1.6549 - accuracy: 0.7020\n",
            "Epoch 33/500\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 1.5604 - accuracy: 0.7450\n",
            "Epoch 34/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 1.4687 - accuracy: 0.8052\n",
            "Epoch 35/500\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 1.3975 - accuracy: 0.8367\n",
            "Epoch 36/500\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 1.3230 - accuracy: 0.8367\n",
            "Epoch 37/500\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 1.2633 - accuracy: 0.8481\n",
            "Epoch 38/500\n",
            "11/11 [==============================] - 2s 189ms/step - loss: 1.1986 - accuracy: 0.8940\n",
            "Epoch 39/500\n",
            "11/11 [==============================] - 2s 220ms/step - loss: 1.1409 - accuracy: 0.9112\n",
            "Epoch 40/500\n",
            "11/11 [==============================] - 2s 136ms/step - loss: 1.0768 - accuracy: 0.9284\n",
            "Epoch 41/500\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 1.0174 - accuracy: 0.9341\n",
            "Epoch 42/500\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.9695 - accuracy: 0.9484\n",
            "Epoch 43/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.9219 - accuracy: 0.9656\n",
            "Epoch 44/500\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.8738 - accuracy: 0.9685\n",
            "Epoch 45/500\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 0.8352 - accuracy: 0.9828\n",
            "Epoch 46/500\n",
            "11/11 [==============================] - 1s 116ms/step - loss: 0.7992 - accuracy: 0.9713\n",
            "Epoch 47/500\n",
            "11/11 [==============================] - 2s 162ms/step - loss: 0.7629 - accuracy: 0.9857\n",
            "Epoch 48/500\n",
            "11/11 [==============================] - 2s 221ms/step - loss: 0.7256 - accuracy: 0.9885\n",
            "Epoch 49/500\n",
            "11/11 [==============================] - 2s 165ms/step - loss: 0.6896 - accuracy: 0.9914\n",
            "Epoch 50/500\n",
            "11/11 [==============================] - 1s 115ms/step - loss: 0.6617 - accuracy: 0.9914\n",
            "Epoch 51/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.6293 - accuracy: 0.9914\n",
            "Epoch 52/500\n",
            "11/11 [==============================] - 1s 115ms/step - loss: 0.6015 - accuracy: 0.9943\n",
            "Epoch 53/500\n",
            "11/11 [==============================] - 1s 113ms/step - loss: 0.5718 - accuracy: 0.9914\n",
            "Epoch 54/500\n",
            "11/11 [==============================] - 1s 113ms/step - loss: 0.5507 - accuracy: 0.9914\n",
            "Epoch 55/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.5255 - accuracy: 0.9943\n",
            "Epoch 56/500\n",
            "11/11 [==============================] - 1s 115ms/step - loss: 0.5063 - accuracy: 0.9914\n",
            "Epoch 57/500\n",
            "11/11 [==============================] - 2s 191ms/step - loss: 0.4822 - accuracy: 0.9914\n",
            "Epoch 58/500\n",
            "11/11 [==============================] - 2s 216ms/step - loss: 0.4606 - accuracy: 0.9943\n",
            "Epoch 59/500\n",
            "11/11 [==============================] - 2s 133ms/step - loss: 0.4407 - accuracy: 0.9943\n",
            "Epoch 60/500\n",
            "11/11 [==============================] - 1s 117ms/step - loss: 0.4205 - accuracy: 0.9943\n",
            "Epoch 61/500\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.4026 - accuracy: 0.9943\n",
            "Epoch 62/500\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 0.3876 - accuracy: 0.9943\n",
            "Epoch 63/500\n",
            "11/11 [==============================] - 1s 115ms/step - loss: 0.3729 - accuracy: 0.9914\n",
            "Epoch 64/500\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 0.3578 - accuracy: 0.9914\n",
            "Epoch 65/500\n",
            "11/11 [==============================] - 1s 116ms/step - loss: 0.3453 - accuracy: 0.9914\n",
            "Epoch 66/500\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.3316 - accuracy: 0.9914\n",
            "Epoch 67/500\n",
            "11/11 [==============================] - 3s 230ms/step - loss: 0.3185 - accuracy: 0.9914\n",
            "Epoch 68/500\n",
            "11/11 [==============================] - 2s 171ms/step - loss: 0.3054 - accuracy: 0.9943\n",
            "Epoch 69/500\n",
            "11/11 [==============================] - 1s 113ms/step - loss: 0.2940 - accuracy: 0.9914\n",
            "Epoch 70/500\n",
            "11/11 [==============================] - 1s 114ms/step - loss: 0.2830 - accuracy: 0.9943\n",
            "Epoch 71/500\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.2749 - accuracy: 0.9914\n",
            "Epoch 72/500\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.2636 - accuracy: 0.9914\n",
            "Epoch 73/500\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.2533 - accuracy: 0.9885\n",
            "Epoch 74/500\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 0.2428 - accuracy: 0.9943\n",
            "Epoch 75/500\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.2342 - accuracy: 0.9943\n",
            "Epoch 76/500\n",
            "11/11 [==============================] - 2s 228ms/step - loss: 0.2262 - accuracy: 0.9914\n",
            "Epoch 77/500\n",
            "11/11 [==============================] - 2s 212ms/step - loss: 0.2176 - accuracy: 0.9943\n",
            "Epoch 78/500\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.2121 - accuracy: 0.9914\n",
            "Epoch 79/500\n",
            "11/11 [==============================] - 1s 117ms/step - loss: 0.2048 - accuracy: 0.9885\n",
            "Epoch 80/500\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 0.1974 - accuracy: 0.9914\n",
            "Epoch 81/500\n",
            "11/11 [==============================] - 1s 115ms/step - loss: 0.1918 - accuracy: 0.9885\n",
            "Epoch 82/500\n",
            "11/11 [==============================] - 1s 113ms/step - loss: 0.1840 - accuracy: 0.9943\n",
            "Epoch 83/500\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.1793 - accuracy: 0.9885\n",
            "Epoch 84/500\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.1737 - accuracy: 0.9943\n",
            "Epoch 85/500\n",
            "11/11 [==============================] - 2s 211ms/step - loss: 0.1685 - accuracy: 0.9914\n",
            "Epoch 86/500\n",
            "11/11 [==============================] - 3s 226ms/step - loss: 0.1631 - accuracy: 0.9914\n",
            "Epoch 87/500\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 0.1581 - accuracy: 0.9885\n",
            "Epoch 88/500\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 0.1530 - accuracy: 0.9914\n",
            "Epoch 89/500\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 0.1483 - accuracy: 0.9943\n",
            "Epoch 90/500\n",
            "11/11 [==============================] - 1s 117ms/step - loss: 0.1445 - accuracy: 0.9943\n",
            "Epoch 91/500\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 0.1411 - accuracy: 0.9885\n",
            "Epoch 92/500\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 0.1361 - accuracy: 0.9943\n",
            "Epoch 93/500\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.1331 - accuracy: 0.9914\n",
            "Epoch 94/500\n",
            "11/11 [==============================] - 3s 237ms/step - loss: 0.1286 - accuracy: 0.9914\n",
            "Epoch 95/500\n",
            "11/11 [==============================] - 3s 245ms/step - loss: 0.1249 - accuracy: 0.9943\n",
            "Epoch 96/500\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.1217 - accuracy: 0.9943\n",
            "Epoch 97/500\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.1190 - accuracy: 0.9885\n",
            "Epoch 98/500\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.1156 - accuracy: 0.9943\n",
            "Epoch 99/500\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.1134 - accuracy: 0.9914\n",
            "Epoch 100/500\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.1101 - accuracy: 0.9914\n",
            "Epoch 101/500\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.1080 - accuracy: 0.9914\n",
            "Epoch 102/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.1059 - accuracy: 0.9914\n",
            "Epoch 103/500\n",
            "11/11 [==============================] - 2s 210ms/step - loss: 0.1019 - accuracy: 0.9914\n",
            "Epoch 104/500\n",
            "11/11 [==============================] - 3s 237ms/step - loss: 0.1008 - accuracy: 0.9885\n",
            "Epoch 105/500\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 0.0973 - accuracy: 0.9943\n",
            "Epoch 106/500\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0957 - accuracy: 0.9914\n",
            "Epoch 107/500\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.0928 - accuracy: 0.9943\n",
            "Epoch 108/500\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0907 - accuracy: 0.9943\n",
            "Epoch 109/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0883 - accuracy: 0.9914\n",
            "Epoch 110/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0871 - accuracy: 0.9943\n",
            "Epoch 111/500\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0859 - accuracy: 0.9914\n",
            "Epoch 112/500\n",
            "11/11 [==============================] - 2s 221ms/step - loss: 0.0831 - accuracy: 0.9943\n",
            "Epoch 113/500\n",
            "11/11 [==============================] - 3s 249ms/step - loss: 0.0814 - accuracy: 0.9914\n",
            "Epoch 114/500\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0798 - accuracy: 0.9914\n",
            "Epoch 115/500\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0781 - accuracy: 0.9914\n",
            "Epoch 116/500\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0766 - accuracy: 0.9943\n",
            "Epoch 117/500\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0747 - accuracy: 0.9943\n",
            "Epoch 118/500\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.0734 - accuracy: 0.9885\n",
            "Epoch 119/500\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 0.0715 - accuracy: 0.9914\n",
            "Epoch 120/500\n",
            "11/11 [==============================] - 1s 115ms/step - loss: 0.0710 - accuracy: 0.9914\n",
            "Epoch 121/500\n",
            "11/11 [==============================] - 2s 189ms/step - loss: 0.0692 - accuracy: 0.9914\n",
            "Epoch 122/500\n",
            "11/11 [==============================] - 3s 235ms/step - loss: 0.0683 - accuracy: 0.9943\n",
            "Epoch 123/500\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 0.0666 - accuracy: 0.9943\n",
            "Epoch 124/500\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0656 - accuracy: 0.9943\n",
            "Epoch 125/500\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0641 - accuracy: 0.9943\n",
            "Epoch 126/500\n",
            "11/11 [==============================] - 1s 116ms/step - loss: 0.0630 - accuracy: 0.9943\n",
            "Epoch 127/500\n",
            "11/11 [==============================] - 1s 114ms/step - loss: 0.0619 - accuracy: 0.9885\n",
            "Epoch 128/500\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 0.0606 - accuracy: 0.9914\n",
            "Epoch 129/500\n",
            "11/11 [==============================] - 1s 117ms/step - loss: 0.0600 - accuracy: 0.9914\n",
            "Epoch 130/500\n",
            "11/11 [==============================] - 2s 178ms/step - loss: 0.0595 - accuracy: 0.9914\n",
            "Epoch 131/500\n",
            "11/11 [==============================] - 3s 233ms/step - loss: 0.0579 - accuracy: 0.9914\n",
            "Epoch 132/500\n",
            "11/11 [==============================] - 2s 161ms/step - loss: 0.0572 - accuracy: 0.9914\n",
            "Epoch 133/500\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0557 - accuracy: 0.9943\n",
            "Epoch 134/500\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0551 - accuracy: 0.9914\n",
            "Epoch 135/500\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.0542 - accuracy: 0.9943\n",
            "Epoch 136/500\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 0.0539 - accuracy: 0.9885\n",
            "Epoch 137/500\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.0525 - accuracy: 0.9914\n",
            "Epoch 138/500\n",
            "11/11 [==============================] - 1s 115ms/step - loss: 0.0523 - accuracy: 0.9943\n",
            "Epoch 139/500\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 0.0508 - accuracy: 0.9943\n",
            "Epoch 140/500\n",
            "11/11 [==============================] - 3s 240ms/step - loss: 0.0508 - accuracy: 0.9943\n",
            "Epoch 141/500\n",
            "11/11 [==============================] - 2s 182ms/step - loss: 0.0501 - accuracy: 0.9914\n",
            "Epoch 142/500\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 0.0487 - accuracy: 0.9943\n",
            "Epoch 143/500\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0484 - accuracy: 0.9914\n",
            "Epoch 144/500\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.0471 - accuracy: 0.9943\n",
            "Epoch 145/500\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 0.0470 - accuracy: 0.9914\n",
            "Epoch 146/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0459 - accuracy: 0.9943\n",
            "Epoch 147/500\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 0.0453 - accuracy: 0.9914\n",
            "Epoch 148/500\n",
            "11/11 [==============================] - 1s 115ms/step - loss: 0.0445 - accuracy: 0.9943\n",
            "Epoch 149/500\n",
            "11/11 [==============================] - 2s 227ms/step - loss: 0.0448 - accuracy: 0.9885\n",
            "Epoch 150/500\n",
            "11/11 [==============================] - 2s 220ms/step - loss: 0.0435 - accuracy: 0.9914\n",
            "Epoch 151/500\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0437 - accuracy: 0.9914\n",
            "Epoch 152/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0421 - accuracy: 0.9943\n",
            "Epoch 153/500\n",
            "11/11 [==============================] - 1s 116ms/step - loss: 0.0427 - accuracy: 0.9885\n",
            "Epoch 154/500\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.0433 - accuracy: 0.9885\n",
            "Epoch 155/500\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0414 - accuracy: 0.9914\n",
            "Epoch 156/500\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 0.0404 - accuracy: 0.9914\n",
            "Epoch 157/500\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0401 - accuracy: 0.9914\n",
            "Epoch 158/500\n",
            "11/11 [==============================] - 3s 260ms/step - loss: 0.0396 - accuracy: 0.9914\n",
            "Epoch 159/500\n",
            "11/11 [==============================] - 2s 220ms/step - loss: 0.0386 - accuracy: 0.9943\n",
            "Epoch 160/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0386 - accuracy: 0.9943\n",
            "Epoch 161/500\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0384 - accuracy: 0.9914\n",
            "Epoch 162/500\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0377 - accuracy: 0.9943\n",
            "Epoch 163/500\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 0.0370 - accuracy: 0.9914\n",
            "Epoch 164/500\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0365 - accuracy: 0.9943\n",
            "Epoch 165/500\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0367 - accuracy: 0.9914\n",
            "Epoch 166/500\n",
            "11/11 [==============================] - 2s 151ms/step - loss: 0.0355 - accuracy: 0.9943\n",
            "Epoch 167/500\n",
            "11/11 [==============================] - 3s 243ms/step - loss: 0.0360 - accuracy: 0.9914\n",
            "Epoch 168/500\n",
            "11/11 [==============================] - 2s 185ms/step - loss: 0.0370 - accuracy: 0.9885\n",
            "Epoch 169/500\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0344 - accuracy: 0.9943\n",
            "Epoch 170/500\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0348 - accuracy: 0.9914\n",
            "Epoch 171/500\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0334 - accuracy: 0.9914\n",
            "Epoch 172/500\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0338 - accuracy: 0.9914\n",
            "Epoch 173/500\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0335 - accuracy: 0.9943\n",
            "Epoch 174/500\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0334 - accuracy: 0.9914\n",
            "Epoch 175/500\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 0.0319 - accuracy: 0.9943\n",
            "Epoch 176/500\n",
            "11/11 [==============================] - 3s 230ms/step - loss: 0.0330 - accuracy: 0.9943\n",
            "Epoch 177/500\n",
            "11/11 [==============================] - 2s 186ms/step - loss: 0.0326 - accuracy: 0.9914\n",
            "Epoch 178/500\n",
            "11/11 [==============================] - 1s 116ms/step - loss: 0.0315 - accuracy: 0.9914\n",
            "Epoch 179/500\n",
            "11/11 [==============================] - 1s 117ms/step - loss: 0.0312 - accuracy: 0.9943\n",
            "Epoch 180/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0307 - accuracy: 0.9914\n",
            "Epoch 181/500\n",
            "11/11 [==============================] - 1s 116ms/step - loss: 0.0305 - accuracy: 0.9943\n",
            "Epoch 182/500\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0303 - accuracy: 0.9943\n",
            "Epoch 183/500\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0296 - accuracy: 0.9943\n",
            "Epoch 184/500\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0298 - accuracy: 0.9885\n",
            "Epoch 185/500\n",
            "11/11 [==============================] - 2s 227ms/step - loss: 0.0296 - accuracy: 0.9943\n",
            "Epoch 186/500\n",
            "11/11 [==============================] - 2s 221ms/step - loss: 0.0301 - accuracy: 0.9914\n",
            "Epoch 187/500\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.0299 - accuracy: 0.9914\n",
            "Epoch 188/500\n",
            "11/11 [==============================] - 1s 116ms/step - loss: 0.0291 - accuracy: 0.9914\n",
            "Epoch 189/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0287 - accuracy: 0.9914\n",
            "Epoch 190/500\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0283 - accuracy: 0.9885\n",
            "Epoch 191/500\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0280 - accuracy: 0.9885\n",
            "Epoch 192/500\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0277 - accuracy: 0.9943\n",
            "Epoch 193/500\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0274 - accuracy: 0.9914\n",
            "Epoch 194/500\n",
            "11/11 [==============================] - 2s 218ms/step - loss: 0.0270 - accuracy: 0.9914\n",
            "Epoch 195/500\n",
            "11/11 [==============================] - 3s 261ms/step - loss: 0.0269 - accuracy: 0.9943\n",
            "Epoch 196/500\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 0.0265 - accuracy: 0.9914\n",
            "Epoch 197/500\n",
            "11/11 [==============================] - 2s 166ms/step - loss: 0.0269 - accuracy: 0.9885\n",
            "Epoch 198/500\n",
            "11/11 [==============================] - 2s 162ms/step - loss: 0.0270 - accuracy: 0.9914\n",
            "Epoch 199/500\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 0.0259 - accuracy: 0.9943\n",
            "Epoch 200/500\n",
            "11/11 [==============================] - 2s 165ms/step - loss: 0.0261 - accuracy: 0.9943\n",
            "Epoch 201/500\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0261 - accuracy: 0.9914\n",
            "Epoch 202/500\n",
            "11/11 [==============================] - 2s 213ms/step - loss: 0.0260 - accuracy: 0.9885\n",
            "Epoch 203/500\n",
            "11/11 [==============================] - 3s 240ms/step - loss: 0.0252 - accuracy: 0.9943\n",
            "Epoch 204/500\n",
            "11/11 [==============================] - 2s 129ms/step - loss: 0.0253 - accuracy: 0.9914\n",
            "Epoch 205/500\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0247 - accuracy: 0.9914\n",
            "Epoch 206/500\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 0.0256 - accuracy: 0.9943\n",
            "Epoch 207/500\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0253 - accuracy: 0.9914\n",
            "Epoch 208/500\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0246 - accuracy: 0.9914\n",
            "Epoch 209/500\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.0240 - accuracy: 0.9943\n",
            "Epoch 210/500\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 0.0237 - accuracy: 0.9914\n",
            "Epoch 211/500\n",
            "11/11 [==============================] - 2s 232ms/step - loss: 0.0241 - accuracy: 0.9943\n",
            "Epoch 212/500\n",
            "11/11 [==============================] - 3s 230ms/step - loss: 0.0233 - accuracy: 0.9943\n",
            "Epoch 213/500\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0230 - accuracy: 0.9943\n",
            "Epoch 214/500\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 0.0230 - accuracy: 0.9943\n",
            "Epoch 215/500\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 0.0230 - accuracy: 0.9885\n",
            "Epoch 216/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0232 - accuracy: 0.9914\n",
            "Epoch 217/500\n",
            "11/11 [==============================] - 1s 117ms/step - loss: 0.0230 - accuracy: 0.9914\n",
            "Epoch 218/500\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 0.0230 - accuracy: 0.9885\n",
            "Epoch 219/500\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 0.0225 - accuracy: 0.9914\n",
            "Epoch 220/500\n",
            "11/11 [==============================] - 2s 233ms/step - loss: 0.0224 - accuracy: 0.9914\n",
            "Epoch 221/500\n",
            "11/11 [==============================] - 3s 248ms/step - loss: 0.0220 - accuracy: 0.9943\n",
            "Epoch 222/500\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0227 - accuracy: 0.9885\n",
            "Epoch 223/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0218 - accuracy: 0.9914\n",
            "Epoch 224/500\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0217 - accuracy: 0.9914\n",
            "Epoch 225/500\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0215 - accuracy: 0.9914\n",
            "Epoch 226/500\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 0.0215 - accuracy: 0.9885\n",
            "Epoch 227/500\n",
            "11/11 [==============================] - 2s 137ms/step - loss: 0.0208 - accuracy: 0.9914\n",
            "Epoch 228/500\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.0213 - accuracy: 0.9943\n",
            "Epoch 229/500\n",
            "11/11 [==============================] - 2s 237ms/step - loss: 0.0213 - accuracy: 0.9914\n",
            "Epoch 230/500\n",
            "11/11 [==============================] - 3s 235ms/step - loss: 0.0211 - accuracy: 0.9943\n",
            "Epoch 231/500\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0208 - accuracy: 0.9914\n",
            "Epoch 232/500\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 0.0205 - accuracy: 0.9943\n",
            "Epoch 233/500\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0202 - accuracy: 0.9943\n",
            "Epoch 234/500\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0205 - accuracy: 0.9914\n",
            "Epoch 235/500\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 0.0198 - accuracy: 0.9914\n",
            "Epoch 236/500\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0205 - accuracy: 0.9914\n",
            "Epoch 237/500\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0200 - accuracy: 0.9914\n",
            "Epoch 238/500\n",
            "11/11 [==============================] - 2s 201ms/step - loss: 0.0198 - accuracy: 0.9885\n",
            "Epoch 239/500\n",
            "11/11 [==============================] - 3s 240ms/step - loss: 0.0195 - accuracy: 0.9914\n",
            "Epoch 240/500\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 0.0205 - accuracy: 0.9885\n",
            "Epoch 241/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0195 - accuracy: 0.9943\n",
            "Epoch 242/500\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0190 - accuracy: 0.9943\n",
            "Epoch 243/500\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0196 - accuracy: 0.9914\n",
            "Epoch 244/500\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 0.0193 - accuracy: 0.9943\n",
            "Epoch 245/500\n",
            "11/11 [==============================] - 1s 117ms/step - loss: 0.0197 - accuracy: 0.9885\n",
            "Epoch 246/500\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.0191 - accuracy: 0.9914\n",
            "Epoch 247/500\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 0.0186 - accuracy: 0.9914\n",
            "Epoch 248/500\n",
            "11/11 [==============================] - 3s 231ms/step - loss: 0.0189 - accuracy: 0.9943\n",
            "Epoch 249/500\n",
            "11/11 [==============================] - 2s 176ms/step - loss: 0.0186 - accuracy: 0.9943\n",
            "Epoch 250/500\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 0.0189 - accuracy: 0.9914\n",
            "Epoch 251/500\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.0184 - accuracy: 0.9914\n",
            "Epoch 252/500\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0182 - accuracy: 0.9943\n",
            "Epoch 253/500\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0180 - accuracy: 0.9943\n",
            "Epoch 254/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0182 - accuracy: 0.9914\n",
            "Epoch 255/500\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0178 - accuracy: 0.9943\n",
            "Epoch 256/500\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0178 - accuracy: 0.9914\n",
            "Epoch 257/500\n",
            "11/11 [==============================] - 2s 223ms/step - loss: 0.0181 - accuracy: 0.9885\n",
            "Epoch 258/500\n",
            "11/11 [==============================] - 2s 224ms/step - loss: 0.0183 - accuracy: 0.9885\n",
            "Epoch 259/500\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0175 - accuracy: 0.9943\n",
            "Epoch 260/500\n",
            "11/11 [==============================] - 1s 117ms/step - loss: 0.0177 - accuracy: 0.9885\n",
            "Epoch 261/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0175 - accuracy: 0.9943\n",
            "Epoch 262/500\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 0.0174 - accuracy: 0.9914\n",
            "Epoch 263/500\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0186 - accuracy: 0.9914\n",
            "Epoch 264/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0168 - accuracy: 0.9943\n",
            "Epoch 265/500\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0169 - accuracy: 0.9914\n",
            "Epoch 266/500\n",
            "11/11 [==============================] - 2s 197ms/step - loss: 0.0167 - accuracy: 0.9943\n",
            "Epoch 267/500\n",
            "11/11 [==============================] - 2s 217ms/step - loss: 0.0171 - accuracy: 0.9914\n",
            "Epoch 268/500\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.0168 - accuracy: 0.9914\n",
            "Epoch 269/500\n",
            "11/11 [==============================] - 1s 116ms/step - loss: 0.0170 - accuracy: 0.9943\n",
            "Epoch 270/500\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 0.0169 - accuracy: 0.9914\n",
            "Epoch 271/500\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 0.0171 - accuracy: 0.9914\n",
            "Epoch 272/500\n",
            "11/11 [==============================] - 1s 116ms/step - loss: 0.0171 - accuracy: 0.9914\n",
            "Epoch 273/500\n",
            "11/11 [==============================] - 1s 117ms/step - loss: 0.0174 - accuracy: 0.9914\n",
            "Epoch 274/500\n",
            "11/11 [==============================] - 1s 117ms/step - loss: 0.0164 - accuracy: 0.9914\n",
            "Epoch 275/500\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 0.0163 - accuracy: 0.9943\n",
            "Epoch 276/500\n",
            "11/11 [==============================] - 2s 224ms/step - loss: 0.0172 - accuracy: 0.9914\n",
            "Epoch 277/500\n",
            "11/11 [==============================] - 2s 187ms/step - loss: 0.0161 - accuracy: 0.9943\n",
            "Epoch 278/500\n",
            "11/11 [==============================] - 1s 115ms/step - loss: 0.0164 - accuracy: 0.9914\n",
            "Epoch 279/500\n",
            "11/11 [==============================] - 1s 114ms/step - loss: 0.0161 - accuracy: 0.9943\n",
            "Epoch 280/500\n",
            "11/11 [==============================] - 1s 115ms/step - loss: 0.0161 - accuracy: 0.9943\n",
            "Epoch 281/500\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0160 - accuracy: 0.9914\n",
            "Epoch 282/500\n",
            "11/11 [==============================] - 1s 117ms/step - loss: 0.0157 - accuracy: 0.9943\n",
            "Epoch 283/500\n",
            "11/11 [==============================] - 1s 115ms/step - loss: 0.0156 - accuracy: 0.9885\n",
            "Epoch 284/500\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0156 - accuracy: 0.9943\n",
            "Epoch 285/500\n",
            "11/11 [==============================] - 2s 198ms/step - loss: 0.0159 - accuracy: 0.9943\n",
            "Epoch 286/500\n",
            "11/11 [==============================] - 3s 227ms/step - loss: 0.0153 - accuracy: 0.9943\n",
            "Epoch 287/500\n",
            "11/11 [==============================] - 2s 139ms/step - loss: 0.0155 - accuracy: 0.9943\n",
            "Epoch 288/500\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0157 - accuracy: 0.9943\n",
            "Epoch 289/500\n",
            "11/11 [==============================] - 1s 117ms/step - loss: 0.0161 - accuracy: 0.9914\n",
            "Epoch 290/500\n",
            "11/11 [==============================] - 1s 117ms/step - loss: 0.0153 - accuracy: 0.9914\n",
            "Epoch 291/500\n",
            "11/11 [==============================] - 1s 116ms/step - loss: 0.0158 - accuracy: 0.9885\n",
            "Epoch 292/500\n",
            "11/11 [==============================] - 1s 116ms/step - loss: 0.0151 - accuracy: 0.9943\n",
            "Epoch 293/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0153 - accuracy: 0.9943\n",
            "Epoch 294/500\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 0.0147 - accuracy: 0.9943\n",
            "Epoch 295/500\n",
            "11/11 [==============================] - 3s 243ms/step - loss: 0.0150 - accuracy: 0.9914\n",
            "Epoch 296/500\n",
            "11/11 [==============================] - 2s 223ms/step - loss: 0.0149 - accuracy: 0.9914\n",
            "Epoch 297/500\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 0.0156 - accuracy: 0.9885\n",
            "Epoch 298/500\n",
            "11/11 [==============================] - 1s 116ms/step - loss: 0.0148 - accuracy: 0.9943\n",
            "Epoch 299/500\n",
            "11/11 [==============================] - 1s 117ms/step - loss: 0.0148 - accuracy: 0.9943\n",
            "Epoch 300/500\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0151 - accuracy: 0.9914\n",
            "Epoch 301/500\n",
            "11/11 [==============================] - 1s 117ms/step - loss: 0.0149 - accuracy: 0.9914\n",
            "Epoch 302/500\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0144 - accuracy: 0.9943\n",
            "Epoch 303/500\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 0.0149 - accuracy: 0.9914\n",
            "Epoch 304/500\n",
            "11/11 [==============================] - 2s 224ms/step - loss: 0.0154 - accuracy: 0.9885\n",
            "Epoch 305/500\n",
            "11/11 [==============================] - 3s 257ms/step - loss: 0.0146 - accuracy: 0.9914\n",
            "Epoch 306/500\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.0146 - accuracy: 0.9943\n",
            "Epoch 307/500\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0143 - accuracy: 0.9943\n",
            "Epoch 308/500\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 0.0141 - accuracy: 0.9943\n",
            "Epoch 309/500\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0145 - accuracy: 0.9914\n",
            "Epoch 310/500\n",
            "11/11 [==============================] - 1s 115ms/step - loss: 0.0141 - accuracy: 0.9914\n",
            "Epoch 311/500\n",
            "11/11 [==============================] - 1s 116ms/step - loss: 0.0145 - accuracy: 0.9914\n",
            "Epoch 312/500\n",
            "11/11 [==============================] - 1s 117ms/step - loss: 0.0143 - accuracy: 0.9943\n",
            "Epoch 313/500\n",
            "11/11 [==============================] - 2s 186ms/step - loss: 0.0142 - accuracy: 0.9914\n",
            "Epoch 314/500\n",
            "11/11 [==============================] - 3s 233ms/step - loss: 0.0141 - accuracy: 0.9943\n",
            "Epoch 315/500\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 0.0147 - accuracy: 0.9943\n",
            "Epoch 316/500\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0137 - accuracy: 0.9943\n",
            "Epoch 317/500\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0145 - accuracy: 0.9914\n",
            "Epoch 318/500\n",
            "11/11 [==============================] - 1s 117ms/step - loss: 0.0139 - accuracy: 0.9914\n",
            "Epoch 319/500\n",
            "11/11 [==============================] - 1s 116ms/step - loss: 0.0153 - accuracy: 0.9885\n",
            "Epoch 320/500\n",
            "11/11 [==============================] - 1s 116ms/step - loss: 0.0143 - accuracy: 0.9943\n",
            "Epoch 321/500\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 0.0137 - accuracy: 0.9943\n",
            "Epoch 322/500\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 0.0143 - accuracy: 0.9914\n",
            "Epoch 323/500\n",
            "11/11 [==============================] - 2s 225ms/step - loss: 0.0144 - accuracy: 0.9914\n",
            "Epoch 324/500\n",
            "11/11 [==============================] - 2s 191ms/step - loss: 0.0137 - accuracy: 0.9914\n",
            "Epoch 325/500\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 0.0136 - accuracy: 0.9943\n",
            "Epoch 326/500\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0133 - accuracy: 0.9914\n",
            "Epoch 327/500\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.0137 - accuracy: 0.9943\n",
            "Epoch 328/500\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 0.0136 - accuracy: 0.9914\n",
            "Epoch 329/500\n",
            "11/11 [==============================] - 1s 115ms/step - loss: 0.0133 - accuracy: 0.9943\n",
            "Epoch 330/500\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0142 - accuracy: 0.9914\n",
            "Epoch 331/500\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 0.0136 - accuracy: 0.9914\n",
            "Epoch 332/500\n",
            "11/11 [==============================] - 2s 216ms/step - loss: 0.0140 - accuracy: 0.9914\n",
            "Epoch 333/500\n",
            "11/11 [==============================] - 2s 204ms/step - loss: 0.0132 - accuracy: 0.9914\n",
            "Epoch 334/500\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0138 - accuracy: 0.9914\n",
            "Epoch 335/500\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0136 - accuracy: 0.9914\n",
            "Epoch 336/500\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0128 - accuracy: 0.9943\n",
            "Epoch 337/500\n",
            "11/11 [==============================] - 1s 117ms/step - loss: 0.0134 - accuracy: 0.9914\n",
            "Epoch 338/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0128 - accuracy: 0.9943\n",
            "Epoch 339/500\n",
            "11/11 [==============================] - 1s 116ms/step - loss: 0.0132 - accuracy: 0.9943\n",
            "Epoch 340/500\n",
            "11/11 [==============================] - 1s 117ms/step - loss: 0.0138 - accuracy: 0.9914\n",
            "Epoch 341/500\n",
            "11/11 [==============================] - 2s 174ms/step - loss: 0.0132 - accuracy: 0.9914\n",
            "Epoch 342/500\n",
            "11/11 [==============================] - 2s 207ms/step - loss: 0.0133 - accuracy: 0.9885\n",
            "Epoch 343/500\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 0.0128 - accuracy: 0.9943\n",
            "Epoch 344/500\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 0.0134 - accuracy: 0.9914\n",
            "Epoch 345/500\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0132 - accuracy: 0.9914\n",
            "Epoch 346/500\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0128 - accuracy: 0.9943\n",
            "Epoch 347/500\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 0.0128 - accuracy: 0.9943\n",
            "Epoch 348/500\n",
            "11/11 [==============================] - 1s 116ms/step - loss: 0.0134 - accuracy: 0.9914\n",
            "Epoch 349/500\n",
            "11/11 [==============================] - 1s 114ms/step - loss: 0.0131 - accuracy: 0.9914\n",
            "Epoch 350/500\n",
            "11/11 [==============================] - 1s 116ms/step - loss: 0.0133 - accuracy: 0.9943\n",
            "Epoch 351/500\n",
            "11/11 [==============================] - 2s 226ms/step - loss: 0.0126 - accuracy: 0.9943\n",
            "Epoch 352/500\n",
            "11/11 [==============================] - 2s 228ms/step - loss: 0.0124 - accuracy: 0.9943\n",
            "Epoch 353/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0126 - accuracy: 0.9914\n",
            "Epoch 354/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0127 - accuracy: 0.9914\n",
            "Epoch 355/500\n",
            "11/11 [==============================] - 1s 116ms/step - loss: 0.0127 - accuracy: 0.9885\n",
            "Epoch 356/500\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 0.0130 - accuracy: 0.9914\n",
            "Epoch 357/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0123 - accuracy: 0.9914\n",
            "Epoch 358/500\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0126 - accuracy: 0.9943\n",
            "Epoch 359/500\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0129 - accuracy: 0.9914\n",
            "Epoch 360/500\n",
            "11/11 [==============================] - 2s 174ms/step - loss: 0.0126 - accuracy: 0.9943\n",
            "Epoch 361/500\n",
            "11/11 [==============================] - 2s 221ms/step - loss: 0.0121 - accuracy: 0.9943\n",
            "Epoch 362/500\n",
            "11/11 [==============================] - 2s 159ms/step - loss: 0.0123 - accuracy: 0.9943\n",
            "Epoch 363/500\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0120 - accuracy: 0.9943\n",
            "Epoch 364/500\n",
            "11/11 [==============================] - 1s 117ms/step - loss: 0.0124 - accuracy: 0.9914\n",
            "Epoch 365/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0123 - accuracy: 0.9914\n",
            "Epoch 366/500\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 0.0119 - accuracy: 0.9943\n",
            "Epoch 367/500\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 0.0133 - accuracy: 0.9943\n",
            "Epoch 368/500\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0128 - accuracy: 0.9914\n",
            "Epoch 369/500\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 0.0123 - accuracy: 0.9914\n",
            "Epoch 370/500\n",
            "11/11 [==============================] - 2s 226ms/step - loss: 0.0119 - accuracy: 0.9914\n",
            "Epoch 371/500\n",
            "11/11 [==============================] - 3s 231ms/step - loss: 0.0121 - accuracy: 0.9914\n",
            "Epoch 372/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0119 - accuracy: 0.9943\n",
            "Epoch 373/500\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0117 - accuracy: 0.9943\n",
            "Epoch 374/500\n",
            "11/11 [==============================] - 1s 116ms/step - loss: 0.0122 - accuracy: 0.9885\n",
            "Epoch 375/500\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 0.0120 - accuracy: 0.9943\n",
            "Epoch 376/500\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0117 - accuracy: 0.9914\n",
            "Epoch 377/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0118 - accuracy: 0.9914\n",
            "Epoch 378/500\n",
            "11/11 [==============================] - 1s 117ms/step - loss: 0.0118 - accuracy: 0.9914\n",
            "Epoch 379/500\n",
            "11/11 [==============================] - 2s 173ms/step - loss: 0.0123 - accuracy: 0.9885\n",
            "Epoch 380/500\n",
            "11/11 [==============================] - 3s 233ms/step - loss: 0.0127 - accuracy: 0.9885\n",
            "Epoch 381/500\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.0118 - accuracy: 0.9943\n",
            "Epoch 382/500\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.0120 - accuracy: 0.9914\n",
            "Epoch 383/500\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 0.0117 - accuracy: 0.9914\n",
            "Epoch 384/500\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 0.0117 - accuracy: 0.9943\n",
            "Epoch 385/500\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 0.0120 - accuracy: 0.9943\n",
            "Epoch 386/500\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0115 - accuracy: 0.9943\n",
            "Epoch 387/500\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 0.0119 - accuracy: 0.9885\n",
            "Epoch 388/500\n",
            "11/11 [==============================] - 2s 178ms/step - loss: 0.0113 - accuracy: 0.9943\n",
            "Epoch 389/500\n",
            "11/11 [==============================] - 3s 236ms/step - loss: 0.0115 - accuracy: 0.9914\n",
            "Epoch 390/500\n",
            "11/11 [==============================] - 2s 164ms/step - loss: 0.0116 - accuracy: 0.9943\n",
            "Epoch 391/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0115 - accuracy: 0.9943\n",
            "Epoch 392/500\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0119 - accuracy: 0.9914\n",
            "Epoch 393/500\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 0.0117 - accuracy: 0.9914\n",
            "Epoch 394/500\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.0115 - accuracy: 0.9914\n",
            "Epoch 395/500\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0113 - accuracy: 0.9914\n",
            "Epoch 396/500\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0115 - accuracy: 0.9914\n",
            "Epoch 397/500\n",
            "11/11 [==============================] - 2s 165ms/step - loss: 0.0112 - accuracy: 0.9943\n",
            "Epoch 398/500\n",
            "11/11 [==============================] - 3s 230ms/step - loss: 0.0122 - accuracy: 0.9885\n",
            "Epoch 399/500\n",
            "11/11 [==============================] - 2s 176ms/step - loss: 0.0116 - accuracy: 0.9914\n",
            "Epoch 400/500\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.0111 - accuracy: 0.9943\n",
            "Epoch 401/500\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0115 - accuracy: 0.9943\n",
            "Epoch 402/500\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0114 - accuracy: 0.9914\n",
            "Epoch 403/500\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0121 - accuracy: 0.9914\n",
            "Epoch 404/500\n",
            "11/11 [==============================] - 1s 115ms/step - loss: 0.0111 - accuracy: 0.9943\n",
            "Epoch 405/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0111 - accuracy: 0.9914\n",
            "Epoch 406/500\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 0.0114 - accuracy: 0.9943\n",
            "Epoch 407/500\n",
            "11/11 [==============================] - 2s 229ms/step - loss: 0.0115 - accuracy: 0.9914\n",
            "Epoch 408/500\n",
            "11/11 [==============================] - 2s 208ms/step - loss: 0.0113 - accuracy: 0.9943\n",
            "Epoch 409/500\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0108 - accuracy: 0.9943\n",
            "Epoch 410/500\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 0.0110 - accuracy: 0.9914\n",
            "Epoch 411/500\n",
            "11/11 [==============================] - 1s 116ms/step - loss: 0.0109 - accuracy: 0.9914\n",
            "Epoch 412/500\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0114 - accuracy: 0.9914\n",
            "Epoch 413/500\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 0.0112 - accuracy: 0.9914\n",
            "Epoch 414/500\n",
            "11/11 [==============================] - 1s 136ms/step - loss: 0.0108 - accuracy: 0.9914\n",
            "Epoch 415/500\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 0.0114 - accuracy: 0.9943\n",
            "Epoch 416/500\n",
            "11/11 [==============================] - 3s 247ms/step - loss: 0.0113 - accuracy: 0.9914\n",
            "Epoch 417/500\n",
            "11/11 [==============================] - 3s 232ms/step - loss: 0.0107 - accuracy: 0.9943\n",
            "Epoch 418/500\n",
            "11/11 [==============================] - 1s 116ms/step - loss: 0.0113 - accuracy: 0.9914\n",
            "Epoch 419/500\n",
            "11/11 [==============================] - 1s 117ms/step - loss: 0.0107 - accuracy: 0.9943\n",
            "Epoch 420/500\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.0112 - accuracy: 0.9885\n",
            "Epoch 421/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0110 - accuracy: 0.9914\n",
            "Epoch 422/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0112 - accuracy: 0.9914\n",
            "Epoch 423/500\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 0.0106 - accuracy: 0.9914\n",
            "Epoch 424/500\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.0110 - accuracy: 0.9943\n",
            "Epoch 425/500\n",
            "11/11 [==============================] - 2s 201ms/step - loss: 0.0110 - accuracy: 0.9914\n",
            "Epoch 426/500\n",
            "11/11 [==============================] - 3s 250ms/step - loss: 0.0105 - accuracy: 0.9943\n",
            "Epoch 427/500\n",
            "11/11 [==============================] - 2s 133ms/step - loss: 0.0112 - accuracy: 0.9943\n",
            "Epoch 428/500\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0107 - accuracy: 0.9914\n",
            "Epoch 429/500\n",
            "11/11 [==============================] - 1s 124ms/step - loss: 0.0109 - accuracy: 0.9914\n",
            "Epoch 430/500\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 0.0108 - accuracy: 0.9914\n",
            "Epoch 431/500\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0106 - accuracy: 0.9943\n",
            "Epoch 432/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0116 - accuracy: 0.9914\n",
            "Epoch 433/500\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.0105 - accuracy: 0.9943\n",
            "Epoch 434/500\n",
            "11/11 [==============================] - 2s 170ms/step - loss: 0.0108 - accuracy: 0.9943\n",
            "Epoch 435/500\n",
            "11/11 [==============================] - 2s 226ms/step - loss: 0.0105 - accuracy: 0.9943\n",
            "Epoch 436/500\n",
            "11/11 [==============================] - 2s 165ms/step - loss: 0.0105 - accuracy: 0.9914\n",
            "Epoch 437/500\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 0.0111 - accuracy: 0.9885\n",
            "Epoch 438/500\n",
            "11/11 [==============================] - 1s 132ms/step - loss: 0.0110 - accuracy: 0.9914\n",
            "Epoch 439/500\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.0104 - accuracy: 0.9943\n",
            "Epoch 440/500\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0108 - accuracy: 0.9914\n",
            "Epoch 441/500\n",
            "11/11 [==============================] - 1s 128ms/step - loss: 0.0103 - accuracy: 0.9943\n",
            "Epoch 442/500\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 0.0109 - accuracy: 0.9914\n",
            "Epoch 443/500\n",
            "11/11 [==============================] - 2s 170ms/step - loss: 0.0110 - accuracy: 0.9914\n",
            "Epoch 444/500\n",
            "11/11 [==============================] - 3s 235ms/step - loss: 0.0106 - accuracy: 0.9943\n",
            "Epoch 445/500\n",
            "11/11 [==============================] - 2s 167ms/step - loss: 0.0111 - accuracy: 0.9943\n",
            "Epoch 446/500\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0106 - accuracy: 0.9943\n",
            "Epoch 447/500\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0106 - accuracy: 0.9943\n",
            "Epoch 448/500\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0107 - accuracy: 0.9914\n",
            "Epoch 449/500\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0110 - accuracy: 0.9914\n",
            "Epoch 450/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0107 - accuracy: 0.9943\n",
            "Epoch 451/500\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 0.0107 - accuracy: 0.9914\n",
            "Epoch 452/500\n",
            "11/11 [==============================] - 2s 141ms/step - loss: 0.0109 - accuracy: 0.9914\n",
            "Epoch 453/500\n",
            "11/11 [==============================] - 2s 225ms/step - loss: 0.0105 - accuracy: 0.9914\n",
            "Epoch 454/500\n",
            "11/11 [==============================] - 2s 215ms/step - loss: 0.0106 - accuracy: 0.9885\n",
            "Epoch 455/500\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0105 - accuracy: 0.9914\n",
            "Epoch 456/500\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 0.0107 - accuracy: 0.9885\n",
            "Epoch 457/500\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 0.0110 - accuracy: 0.9914\n",
            "Epoch 458/500\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 0.0105 - accuracy: 0.9943\n",
            "Epoch 459/500\n",
            "11/11 [==============================] - 1s 123ms/step - loss: 0.0104 - accuracy: 0.9914\n",
            "Epoch 460/500\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.0101 - accuracy: 0.9943\n",
            "Epoch 461/500\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.0103 - accuracy: 0.9914\n",
            "Epoch 462/500\n",
            "11/11 [==============================] - 2s 222ms/step - loss: 0.0104 - accuracy: 0.9914\n",
            "Epoch 463/500\n",
            "11/11 [==============================] - 3s 233ms/step - loss: 0.0104 - accuracy: 0.9943\n",
            "Epoch 464/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0102 - accuracy: 0.9914\n",
            "Epoch 465/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0104 - accuracy: 0.9885\n",
            "Epoch 466/500\n",
            "11/11 [==============================] - 1s 121ms/step - loss: 0.0105 - accuracy: 0.9885\n",
            "Epoch 467/500\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.0101 - accuracy: 0.9914\n",
            "Epoch 468/500\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.0108 - accuracy: 0.9914\n",
            "Epoch 469/500\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 0.0105 - accuracy: 0.9914\n",
            "Epoch 470/500\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0107 - accuracy: 0.9885\n",
            "Epoch 471/500\n",
            "11/11 [==============================] - 2s 196ms/step - loss: 0.0101 - accuracy: 0.9914\n",
            "Epoch 472/500\n",
            "11/11 [==============================] - 2s 221ms/step - loss: 0.0101 - accuracy: 0.9943\n",
            "Epoch 473/500\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 0.0101 - accuracy: 0.9943\n",
            "Epoch 474/500\n",
            "11/11 [==============================] - 1s 117ms/step - loss: 0.0102 - accuracy: 0.9914\n",
            "Epoch 475/500\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0102 - accuracy: 0.9943\n",
            "Epoch 476/500\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 0.0102 - accuracy: 0.9914\n",
            "Epoch 477/500\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 0.0107 - accuracy: 0.9943\n",
            "Epoch 478/500\n",
            "11/11 [==============================] - 1s 118ms/step - loss: 0.0099 - accuracy: 0.9943\n",
            "Epoch 479/500\n",
            "11/11 [==============================] - 1s 120ms/step - loss: 0.0106 - accuracy: 0.9914\n",
            "Epoch 480/500\n",
            "11/11 [==============================] - 2s 163ms/step - loss: 0.0100 - accuracy: 0.9943\n",
            "Epoch 481/500\n",
            "11/11 [==============================] - 2s 223ms/step - loss: 0.0103 - accuracy: 0.9914\n",
            "Epoch 482/500\n",
            "11/11 [==============================] - 2s 170ms/step - loss: 0.0101 - accuracy: 0.9914\n",
            "Epoch 483/500\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 0.0100 - accuracy: 0.9943\n",
            "Epoch 484/500\n",
            "11/11 [==============================] - 1s 125ms/step - loss: 0.0101 - accuracy: 0.9914\n",
            "Epoch 485/500\n",
            "11/11 [==============================] - 1s 119ms/step - loss: 0.0102 - accuracy: 0.9885\n",
            "Epoch 486/500\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 0.0102 - accuracy: 0.9914\n",
            "Epoch 487/500\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.0102 - accuracy: 0.9943\n",
            "Epoch 488/500\n",
            "11/11 [==============================] - 1s 116ms/step - loss: 0.0101 - accuracy: 0.9914\n",
            "Epoch 489/500\n",
            "11/11 [==============================] - 2s 137ms/step - loss: 0.0099 - accuracy: 0.9943\n",
            "Epoch 490/500\n",
            "11/11 [==============================] - 3s 249ms/step - loss: 0.0101 - accuracy: 0.9885\n",
            "Epoch 491/500\n",
            "11/11 [==============================] - 2s 205ms/step - loss: 0.0103 - accuracy: 0.9914\n",
            "Epoch 492/500\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.0101 - accuracy: 0.9885\n",
            "Epoch 493/500\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.0102 - accuracy: 0.9943\n",
            "Epoch 494/500\n",
            "11/11 [==============================] - 1s 135ms/step - loss: 0.0097 - accuracy: 0.9943\n",
            "Epoch 495/500\n",
            "11/11 [==============================] - 1s 134ms/step - loss: 0.0102 - accuracy: 0.9914\n",
            "Epoch 496/500\n",
            "11/11 [==============================] - 1s 122ms/step - loss: 0.0099 - accuracy: 0.9943\n",
            "Epoch 497/500\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.0097 - accuracy: 0.9943\n",
            "Epoch 498/500\n",
            "11/11 [==============================] - 2s 142ms/step - loss: 0.0102 - accuracy: 0.9914\n",
            "Epoch 499/500\n",
            "11/11 [==============================] - 2s 222ms/step - loss: 0.0099 - accuracy: 0.9943\n",
            "Epoch 500/500\n",
            "11/11 [==============================] - 2s 198ms/step - loss: 0.0102 - accuracy: 0.9914\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7da383f5f760>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=500, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "dc30fe17",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc30fe17",
        "outputId": "79fb0ab7-b97d-4c72-83a0-5f1523df9f85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8, 155, 156, 21]\n",
            "1/1 [==============================] - 0s 452ms/step\n",
            "[8, 155, 156, 21, 157]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "[8, 155, 156, 21, 157, 158]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "[8, 155, 156, 21, 157, 158, 2]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "[8, 155, 156, 21, 157, 158, 2, 140]\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "[8, 155, 156, 21, 157, 158, 2, 140, 141]\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "bengaluru faces challenges like traffic congestion and welcoming nature readily\n"
          ]
        }
      ],
      "source": [
        "input_text = \"bengaluru faces challenges like\"\n",
        "predict_next_words= 6\n",
        "\n",
        "for _ in range(predict_next_words):\n",
        "    token_list = mytokenizer.texts_to_sequences([input_text])[0]\n",
        "    print(token_list)\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    predicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "    output_word = \"\"\n",
        "    for word, index in mytokenizer.word_index.items():\n",
        "        if index == predicted:\n",
        "            output_word = word\n",
        "            break\n",
        "    input_text += \" \" + output_word\n",
        "\n",
        "print(input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "c2b46fa7",
      "metadata": {
        "id": "c2b46fa7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}